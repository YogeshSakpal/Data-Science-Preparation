{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive Integrated Moving Average Model\n",
    "An ARIMA model is a class of statistical models for analyzing and forecasting time series data.\n",
    "\n",
    "It explicitly caters to a suite of standard structures in time series data, and as such provides a simple yet powerful method for making skillful time series forecasts.\n",
    "\n",
    "ARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. It is a generalization of the simpler AutoRegressive Moving Average and adds the notion of integration.\n",
    "\n",
    "This acronym is descriptive, capturing the key aspects of the model itself. Briefly, they are:\n",
    "\n",
    "#### AR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.\n",
    "\n",
    "#### I: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\n",
    "\n",
    "#### MA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n",
    "\n",
    "Each of these components are explicitly specified in the model as a parameter. A standard notation is used of ARIMA(p,d,q) where the parameters are substituted with integer values to quickly indicate the specific ARIMA model being used.\n",
    "\n",
    "The parameters of the ARIMA model are defined as follows:\n",
    "\n",
    "##### p: The number of lag observations included in the model, also called the lag order.\n",
    "##### d: The number of times that the raw observations are differenced, also called the degree of differencing.\n",
    "##### q: The size of the moving average window, also called the order of moving average.\n",
    "\n",
    "A linear regression model is constructed including the specified number and type of terms, and the data is prepared by a degree of differencing in order to make it stationary, i.e. to remove trend and seasonal structures that negatively affect the regression model.\n",
    "\n",
    "A value of 0 can be used for a parameter, which indicates to not use that element of the model. This way, the ARIMA model can be configured to perform the function of an ARMA model, and even a simple AR, I, or MA model.\n",
    "\n",
    "Adopting an ARIMA model for a time series assumes that the underlying process that generated the observations is an ARIMA process. This may seem obvious, but helps to motivate the need to confirm the assumptions of the model in the raw observations and in the residual errors of forecasts from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this article, we will cover:\n",
    "\n",
    "1. Methods used for converting non-stationary data into stationary data,\n",
    "2. The ARIMA model,\n",
    "3. The SARIMA model,\n",
    "\n",
    "A real-world example of predicting the stock price of Microsoft,\n",
    "Some hyper-parameter tuning to make the model more robust.\n",
    "So, in machine learning, when the data is not in a Gaussian distribution we typically employ transformations like BOX-COX, or LOG. Similarly, when we have non-stationary time series data, there are two types of techniques to convert into stationary time series:\n",
    "\n",
    "1. Differencing\n",
    "2. Transformations\n",
    "\n",
    "# Differencing\n",
    "Differencing is one of the most important strategies to make a time series stationary. How does it work? \n",
    "\n",
    "Let me give you the intuition:\n",
    "\n",
    "y' = yt - yt-1 .....................................................1st order Differentiation \n",
    "\n",
    "Differencing says instead of predicting yt directly try to predict the gap between yt and yt-1:\n",
    "\n",
    "Differencing is very similar to differentiation. Yt‚Äô is nothing but yt  ‚Äì yt-1. If the time series is non-stationary, taking the difference is a great way. Now, instead of predicting yt  predict Yt‚Äô\n",
    "\n",
    "Because we can predict  Yt‚Äô we can compute yt as:\n",
    "\n",
    "yt  =  Yt‚Äô + yt-1   (Reconstruction)\n",
    "\n",
    "Research has shown that Yt‚Äô is typically more likely to be stationary than yt itself. Given \n",
    "\n",
    "y1 , y2, y3, y4, . . . . . . . . . . . yt, yt ‚Äì 1, yt + 1  ‚Äî-> Non stationary\n",
    "\n",
    "Now we take the difference between y1 and y2 let‚Äôs call it y1‚Äô.\n",
    "\n",
    "Similarly, we take the difference between y2 and y3 let‚Äôs call it y2‚Äô.\n",
    "\n",
    "So on yt‚Äô.\n",
    "\n",
    "y1‚Äô, y2‚Äô, y3‚Äô, . . . . . . . . . . . . yt‚Äô   ‚Äî->  1st order difference (more likely to be stationary)\n",
    "\n",
    "Instead of using 1st  order differentiation values, why not use 2nd order differentiation values?\n",
    "\n",
    "Y1‚Äô‚Äô , y2‚Äô‚Äô, y3‚Äô‚Äô, . . . . . . . . . . . . yt‚Äô‚Äô \n",
    "\n",
    "y\" = y't - y't-1      2nd  order differentiation.\n",
    "\n",
    "If we plugin the formula for  yt‚Äô in 2nd order differentiation, we get:\n",
    "\n",
    "y\" = yt - 2yt-1 + yt-2\n",
    "\n",
    "Now we can construct y1 from the above equation as:\n",
    "\n",
    "yt = y\"+2yt-1 - yt-2\n",
    "\n",
    "If your time series data is non-stationary, use differencing. It‚Äôs an extremely powerful technique. If the 1st order differentiation doesn‚Äôt work, you can use 2nd order differencing.\n",
    "\n",
    "We can do Dth order differencing. This is the hyper-parameter here. We need to experiment with  1st, 2nd, 3rd so on to find the best value.\n",
    "\n",
    "# Log-Transform\n",
    "\n",
    "Differencing works very well with practical time series data. But it can‚Äôt be applied to all time series. There are other methods, like Log transform, just like there are different methods to convert data into a Gaussian distribution. Log transforms are some of the most popular transforms used.\n",
    "\n",
    "In Log transforms, instead of modeling yt points, try to apply the logarithmic function to a point, and model the time series with the new log-transformed data. Let‚Äôs called the new point ·ªπt(y Tilda)\n",
    "\n",
    "·ªπt = log(yt)\n",
    "\n",
    "All of these methods are from the 1970s, before modern computers took off or modern machine learning came into existence. The above two are the most popular methods to convert time series into stationary data. Of course, there are plenty of other methods that you can employ depending on your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA(p,q,d)\n",
    "\n",
    "ARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. It‚Äôs a class of models that captures a suite of different standard temporal structures in time series data. It explicitly caters to a suite of standard structures in time-series data, and as such provides a simple, powerful method for making skillful time-series forecasts. It‚Äôs a generalization of the simpler AutoRegressive Moving Average, with the added notion of integration.\n",
    "\n",
    "\n",
    "Auto Regressive<================================      ============================================>Moving Average\n",
    "                                                \"     \"\n",
    "                                                \"     \"\n",
    "                                                \"     \"\n",
    "                                                \"     \"\n",
    "                                                \"     \"\n",
    "                                                \"     \"\n",
    "                                                 ARIMA\n",
    "                                                   \"\n",
    "                                                   \"\n",
    "                                                   \"\n",
    "                                                   \"\n",
    "                                                   \"\n",
    "                                              Interegrated (Opposite to differencing)\n",
    "                                              \n",
    "\n",
    "# How does the ARIMA model work?\n",
    "Simply put, we have 3 parameters in ARIMA(p,q,d). \n",
    "\n",
    "p is from Auto Regression, q is from Moving Averages, and d is from differencing. \n",
    "\n",
    "d can be any order of differencing. \n",
    "\n",
    "All three parameters are hyper-parameters that need to experiment and figure out which fits best, just like K in K-NN. If d = 2 instead of predicting yt we will use yt‚Äô‚Äô to model.\n",
    "\n",
    "Now we have ARMA(p,q). What is ARMA? ARMA is ARIMA without the I, the Integrating part. \n",
    "\n",
    "p corresponding to AR and q corresponding to MA. The model looks like this:\n",
    "\n",
    "Here, Œº is some constant + linear combination of the previous p + linear combination of the previous q errored terms + the error this time(ùúñt).\n",
    "\n",
    "What happens if we take ùúñt to the other side of the equation? This becomes:\n",
    "\n",
    "This equation is the same as the previous equation. We have a constant + linear combination of previous P values + linear combination of previous errored terms.\n",
    "\n",
    "Imagine how we can model this into Linear Regression? We‚Äôll take the previous p values as features, and previous q errors as features, ùù∞i and ùû±j will be linear regression. This is also a linear regression problem. We can say ARIMA is nothing but a linear regression.\n",
    "\n",
    "In a nutshell, ARIMA is:\n",
    "\n",
    "1. P, q, d are hyper-parameters,\n",
    "2. ARIMA(p, q, d) is a linear regression model on previous p values and previous q errors post differencing d times,\n",
    "3. Also know as the Box-Jenkins model(1976).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "1. https://neptune.ai/blog/time-series-forecasting\n",
    "2. https://machinelearningmastery.com/sarima-for-time-series-forecasting-in-python/\n",
    "3. https://facebook.github.io/prophet/\n",
    "4. https://en.wikipedia.org/wiki/Power_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
